{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NS Shop+편성데이터(NS홈쇼핑) 를 활용하여 방송편성표에 따른\n",
    "# 판매실적을 예측하고, 최적 수익을 고려한 요일별/ 시간대별 / 카테고리별 편성\n",
    "# 최적화 방안(모형) 제시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "%matplotlib inline\n",
    "# 데이터 프레임 자리수 표기\n",
    "# pd.options.display.float_format = '{:.5f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "실적데이터1 = pd.read_excel(\n",
    "    r'./01_학습데이터/2020 빅콘테스트 데이터분석분야-챔피언리그_2019년 실적데이터_v1_200818.xlsx', header=1)\n",
    "시청률데이터1 = pd.read_excel(\n",
    "    r'./01_학습데이터/2020 빅콘테스트 데이터분석분야-챔피언리그_시청률 데이터.xlsx', header=1)\n",
    "평가데이터1 = pd.read_excel(\n",
    "    r'./02_평가데이터/2020 빅콘테스트 데이터분석분야-챔피언리그_2020년 6월 판매실적예측데이터(평가데이터).xlsx', header=1)\n",
    "기온데이터1 = pd.read_excel(\n",
    "    r'./01_학습데이터/기온.xlsx', header=0, encoding='euc-kr')\n",
    "강수량데이터1 = pd.read_excel(\n",
    "    r'./01_학습데이터/강수량.xlsx', header=0, encoding='euc-kr')\n",
    "풍속데이터1 = pd.read_excel(\n",
    "    r'./01_학습데이터/풍속.xlsx', header=0, encoding='euc-kr')\n",
    "주가데이터1 = pd.read_csv(\n",
    "    r'./01_학습데이터/주가데이터.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 기본 전처리 & 분석에 용이하게 컬럼 형태 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "실적데이터=실적데이터1.copy()\n",
    "시청률데이터=시청률데이터1.copy()\n",
    "평가데이터=평가데이터1.copy()\n",
    "\n",
    "# 데이터 전처리\n",
    "실적데이터.rename(columns={'노출(분)' : '노출'}, inplace=True)\n",
    "\n",
    "# 결측값 처리 \n",
    "# 1. 판매단가가 0인 데이터 제거\n",
    "실적데이터.취급액.fillna(0, inplace=True)\n",
    "\n",
    "# 2. 노출값이 nan인 항목은 바로 위 항목으로 채우기\n",
    "실적데이터.노출.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# 2019년 데이터만 분석할 예정 -> 2020년 데이터 제거(10개 내외)\n",
    "실적데이터=실적데이터[실적데이터.방송일시<'2020-01-01']\n",
    "\n",
    "# 판매가 0원인 상품 제거(무형)\n",
    "실적데이터=실적데이터[실적데이터.판매단가!=0]\n",
    "\n",
    "# 예측변수(종속변수)를 취급액 대신 주문량 사용\n",
    "# 주문량 = 취급액 / 판매단가 round(x[1]/x[0], 3) if x[0]!=0 else 0\n",
    "실적데이터['주문량'] = (실적데이터.취급액/실적데이터.판매단가).fillna(0)\n",
    "\n",
    "# 방송일시 컬럼 나눠서 데이터형식 변경\n",
    "실적데이터['월']=실적데이터.방송일시.dt.month\n",
    "실적데이터['일']=실적데이터.방송일시.dt.day\n",
    "실적데이터['요일']=실적데이터.방송일시.dt.weekday\n",
    "실적데이터['주']=실적데이터.방송일시.dt.week\n",
    "실적데이터['시간']=실적데이터.방송일시.dt.time\n",
    "실적데이터['시']=실적데이터.방송일시.dt.hour\n",
    "실적데이터['분']=실적데이터.방송일시.dt.minute\n",
    "\n",
    "# 파생변수 생성 및 외부데이터 결합을 위한 추가변수 생성\n",
    "실적데이터['방송날짜'] = 실적데이터.방송일시.apply(lambda x : str(x)).apply(lambda x : x.split(' ')[0])\n",
    "실적데이터['방송시간'] = 실적데이터.방송일시.apply(lambda x : str(x)).apply(lambda x : x.split(' ')[1][:-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 외부데이터 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 날씨데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날씨 데이터 전처리\n",
    "기온데이터=기온데이터1[['일시','평균최고기온(℃)', '평균최저기온(℃)']] #'평균기온(℃)',\n",
    "강수량데이터=강수량데이터1[['일시','평균일강수량(mm)']] # ,'최다일강수량(mm)', '1시간최다강수량(mm)'\n",
    "풍속데이터=풍속데이터1[['일시','최대풍속(m/s)']] # ,'평균풍속(m/s)', '최대순간풍속(m/s)'\n",
    "\n",
    "기온데이터=기온데이터.sort_values(by='일시')\n",
    "강수량데이터=강수량데이터.sort_values(by='일시')\n",
    "풍속데이터=풍속데이터.sort_values(by='일시')\n",
    "\n",
    "기온데이터.index=list(range(365))\n",
    "강수량데이터.index=list(range(365))\n",
    "풍속데이터.index=list(range(365))\n",
    "\n",
    "기온데이터.일시=기온데이터.일시.map(lambda x : str(x).split(\" \")[0])\n",
    "강수량데이터.일시=강수량데이터.일시.map(lambda x : str(x).split(\" \")[0])\n",
    "풍속데이터.일시=pd.to_datetime(풍속데이터.일시).map(lambda x : str(x).split(\" \")[0])\n",
    "\n",
    "강수량데이터.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날씨데이터 합치기\n",
    "\n",
    "실적데이터=실적데이터.rename(columns={'방송날짜':'일시'})\n",
    "\n",
    "실적데이터=pd.merge(실적데이터, 기온데이터, on='일시')\n",
    "실적데이터=pd.merge(실적데이터, 강수량데이터, on='일시')\n",
    "실적데이터=pd.merge(실적데이터, 풍속데이터, on='일시')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 시청률데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시청률데이터 전처리\n",
    "시청률데이터.set_index('시간대', inplace=True)\n",
    "시청률데이터.rename(columns={'2019-01-01 to 2019-12-31' : '년평균'}, inplace=True)\n",
    "시청률데이터.rename(index={'월화수목금토일02:00-01:59' : '일평균'}, inplace=True)\n",
    "시청률데이터2 = 시청률데이터.loc[:\"01:59\",:\"2019-12-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 방송일시별 분당평균시청률 구하기\n",
    "분당평균시청률=[]\n",
    "for i in range(len(실적데이터)):\n",
    "    시작=실적데이터.방송시간.iloc[i]\n",
    "    종료=str(pd.to_datetime(실적데이터.방송시간.iloc[i])+datetime.timedelta(minutes=round(float(실적데이터.노출.iloc[i]),0)-1)).split(\" \")[1][:-3]\n",
    "    분당평균시청률.append((시청률데이터2[실적데이터.일시.iloc[i]].loc[시작:종료].mean()))\n",
    "    \n",
    "분당최고시청률=[]\n",
    "for i in range(len(실적데이터)):\n",
    "    시작=실적데이터.방송시간.iloc[i]\n",
    "    종료=str(pd.to_datetime(실적데이터.방송시간.iloc[i])+datetime.timedelta(minutes=round(float(실적데이터.노출.iloc[i]),0)-1)).split(\" \")[1][:-3]\n",
    "    분당최고시청률.append((시청률데이터2[실적데이터.일시.iloc[i]].loc[시작:종료].max()))\n",
    "\n",
    "# 분당평균시청률\n",
    "실적데이터['분당평균시청률']=분당평균시청률\n",
    "실적데이터['분당최고시청률']=분당최고시청률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 주가데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "주가데이터 = 주가데이터1.sort_values(by = '날짜')\n",
    "\n",
    "# 2019년 00월 00일 리스트 생성\n",
    "a = []\n",
    "for i in range(13):\n",
    "    if i in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        for j in range(1, 32):\n",
    "            if i < 10:\n",
    "                s1 = '0'+ str(i)\n",
    "            else:\n",
    "                s1 = str(i)\n",
    "            if j < 10:\n",
    "                s2 = '0'+ str(j)\n",
    "            else:\n",
    "                s2 = str(j)\n",
    "            a.append(\"2019년 {}월 {}일\".format(s1, s2))\n",
    "    elif i in [4, 6, 9, 11]:\n",
    "        for j in range(1, 31):\n",
    "            if i < 10:\n",
    "                s1 = '0'+ str(i) \n",
    "            else:\n",
    "                s1 = str(i)\n",
    "            if j < 10:\n",
    "                s2 = '0'+ str(j)\n",
    "            else:\n",
    "                s2 = str(j)\n",
    "            a.append(\"2019년 {}월 {}일\".format(s1, s2))\n",
    "    elif i == 2:\n",
    "        for j in range(1, 29):\n",
    "            if i < 10:\n",
    "                s1 = '0'+ str(i) \n",
    "            else:\n",
    "                s1 = str(i)\n",
    "            if j < 10:\n",
    "                s2 = '0'+ str(j)\n",
    "            else:\n",
    "                s2 = str(j)\n",
    "            a.append(\"2019년 {}월 {}일\".format(s1, s2))\n",
    "\n",
    "# 주가데이터의 빈 날짜를 a 리스트와 merge를 통해 채움\n",
    "# 날짜 위에서 아래로 1월 1일 ~ 12월 31일\n",
    "a=pd.DataFrame(a)\n",
    "a.columns=['날짜']\n",
    "주가데이터2 = pd.merge(주가데이터, a, on='날짜', how='outer')\n",
    "주가데이터2 = 주가데이터2.sort_values(by='날짜')\n",
    "\n",
    "# 주가데이터 빈 행은 위아래 행으로 채움\n",
    "주가데이터2 = 주가데이터2.fillna(method = 'ffill')\n",
    "주가데이터2 = 주가데이터2.fillna(method = 'bfill')\n",
    "\n",
    "# 거래량 K 지우고 1000해서 구함\n",
    "주가데이터2.거래량=주가데이터2.거래량.map(lambda x : x[:-1])\n",
    "주가데이터2.거래량=pd.to_numeric(주가데이터2.거래량)\n",
    "주가데이터2.거래량=주가데이터2.거래량*1000\n",
    "\n",
    "temp = pd.concat([실적데이터.pivot_table(index=['월','일'], values='주문량', aggfunc='mean').reset_index(), 주가데이터2.종가], axis=1)\n",
    "temp.종가 = pd.to_numeric(temp.종가.map(lambda X: X.replace(\",\",\"\")))\n",
    "\n",
    "temp.drop(['주문량'], axis=1, inplace=True)\n",
    "\n",
    "실적데이터=pd.merge(실적데이터, temp, on=['월','일'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평일/주말, 수목금토\n",
    "# 실적데이터['주말']=실적데이터.요일.map(lambda x :1 if x in [5,6] else 0)\n",
    "# 실적데이터['수목금토']=실적데이터.요일.map(lambda x :1 if x in [2,3,4,5] else 0)\n",
    "\n",
    "# 일\n",
    "# 실적데이터['월말초'] = 실적데이터.일.map(lambda X: X in [1,2,3,4,5,6,26,27,28,29,30,31]).map(lambda X: 1 if X else 0)\n",
    "# 실적데이터['26-28']=실적데이터.일.map(lambda x :1 if x in [26,27,28] else 0)\n",
    "\n",
    "# 시간대별 상품군별 평균 주문량의 추세를 비교. 밤/새벽(19-02), 오전(6-12), 오후(12-19) 컬럼 생성\n",
    "# 실적데이터['밤/새벽(19-02)']=실적데이터.시.map(lambda x : 1 if x <= 2 or x >= 19 else 0)\n",
    "# 실적데이터['오전(6-12)']=실적데이터.시.map(lambda x : 1 if 6 <= x <= 12 else 0)\n",
    "# 실적데이터['오후(12-19)']=실적데이터.시.map(lambda x : 1 if 12 < x < 19 else 0)\n",
    "\n",
    "# 10-15,20이후\n",
    "# 실적데이터['10-15,20이후']=실적데이터.시.map(lambda x : 1 if 10 <= x <= 15 or x >= 20 else 0)\n",
    "\n",
    "# 3시간 단위\n",
    "# 실적데이터['0-2시']=실적데이터.시.map(lambda x : 1 if 0 <= x < 3 else 0)\n",
    "# 실적데이터['3-5시']=실적데이터.시.map(lambda x : 1 if 3 <= x < 5 else 0)\n",
    "# 실적데이터['6-8시']=실적데이터.시.map(lambda x : 1 if 6 <= x < 9 else 0)\n",
    "# 실적데이터['9-11시']=실적데이터.시.map(lambda x : 1 if 9 <= x < 12 else 0)\n",
    "# 실적데이터['12-14시']=실적데이터.시.map(lambda x : 1 if 12 <= x < 15 else 0)\n",
    "# 실적데이터['15-17시']=실적데이터.시.map(lambda x : 1 if 15 <= x < 18 else 0)\n",
    "# 실적데이터['18-20시']=실적데이터.시.map(lambda x : 1 if 18 <= x < 21 else 0)\n",
    "# 실적데이터['21-23시']=실적데이터.시.map(lambda x : 1 if 21 <= x < 24 else 0)\n",
    "\n",
    "#  7,8,9, 15-18\n",
    "# 실적데이터['789,15-18']=실적데이터.시.map(lambda x :  1 if x in [7,8,9,15,16,17,18] else 0)\n",
    "\n",
    "# 6시 부터 밤 9시\n",
    "# 실적데이터['6-21시']=실적데이터.시.map(lambda x : 1 if 6 <= x < 22 else 0)\n",
    "\n",
    "# 15-17\n",
    "# 실적데이터['15-17시']=실적데이터.시.map(lambda x : 1 if 15 <= x < 18 else 0)\n",
    "\n",
    "# 계절\n",
    "# 실적데이터['봄']=실적데이터.월.map(lambda x : 1 if x in [3,4,5] else 0)\n",
    "# 실적데이터['여름']=실적데이터.월.map(lambda x :  1 if x in [6,7,8] else 0)\n",
    "# 실적데이터['가을']=실적데이터.월.map(lambda x :  1 if x in [9,10,11] else 0)\n",
    "# 실적데이터['겨울']=실적데이터.월.map(lambda x :  1 if x in [12,1,2] else 0)\n",
    "\n",
    "# 상하반기\n",
    "# 실적데이터['상반기']=실적데이터.월.map(lambda x : 1 if  x in [1,2,3,4,5,6] else 0)\n",
    "\n",
    "# 7,8,9월 추세에 따른\n",
    "# 실적데이터['월789']=실적데이터.월.map(lambda x :  1 if x in [7,8,9] else 0)\n",
    "# 6-10월\n",
    "# 실적데이터['월610'] = 실적데이터.월.map(lambda X: X in [6,7,8,9,10]).map(lambda X: 1 if X else 0)\n",
    "# 11-12월\n",
    "# 실적데이터['월1112'] = 실적데이터.월.map(lambda X: X in [11,12]).map(lambda X: 1 if X else 0)\n",
    "\n",
    "\n",
    "# 실적데이터['월6-10']=실적데이터.월.map(lambda x :  1 if x in [6,7,8,9,10] else 0)\n",
    "# 실적데이터['월11-12']=실적데이터.월.map(lambda x :  1 if x in [11,12] else 0)\n",
    "\n",
    "# 노출\n",
    "# 실적데이터['노출20미만']=실적데이터.노출.map(lambda x : 1 if x < 20 else 0)\n",
    "# 실적데이터['노출20이상']=실적데이터.노출.map(lambda x : 1 if 20 <= x < 30 else 0)\n",
    "# 실적데이터['노출30이상']=실적데이터.노출.map(lambda x : 1 if x >= 30 else 0)\n",
    "\n",
    "# 주\n",
    "# 실적데이터['주32이상']=실적데이터.주.map(lambda x : 1 if x >= 32 else 0)\n",
    "\n",
    "# 168시간 기준\n",
    "# 실적데이터['168시간기준']=실적데이터.방송일시.dt.weekday*24+실적데이터.방송일시.dt.hour\n",
    "\n",
    "# 판매단가 분포에 따른 분류\n",
    "# 실적데이터['저가'] = 실적데이터.판매단가.map(lambda X: 1 if X <=30000 else 0)\n",
    "# 실적데이터['중가'] = 실적데이터.판매단가.map(lambda X: 1 if 30000< X <= 400000  else 0)\n",
    "# 실적데이터['고가'] = 실적데이터.판매단가.map(lambda X: 1 if X >400000  else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브랜드 컬럼\n",
    "\n",
    "# 상품명에서 불필요한 단어 제거\n",
    "list1 = []\n",
    "for item in 실적데이터[['상품명']].values:\n",
    "    for i in ['(직매입)', '일시불', '무이자', '도냄', 'a4', '뉴', '(일)', '(무)', '특집', '(쿠)',\n",
    "              '초특가''(세일20%)', '1세트', '2세트', '(더블+더블)', '(더블+싱글)', '(더블사이즈)', \n",
    "              '(싱글사이즈)', '(점보특대형)', '(점보형)', '(중형)', '(퀸+퀸)', '(퀸+싱글)', '(싱글+싱글)', \n",
    "              '(킹사이즈)', '(퀸사이즈)', '[완벽더블]', '파격가', '초특가', '무)', '(렌탈)', '국내산']:\n",
    "        item[0] = item[0].replace(i, \"\")\n",
    "    list1.append(item[0].strip())\n",
    "\n",
    "# 숫자, 영어, 한글을 제외한 문자 제거\n",
    "list3 = []\n",
    "for i in list1:\n",
    "    result_string = \"\"\n",
    "    for c in i:\n",
    "        if c == \" \":\n",
    "            result_string += c\n",
    "        elif c.isalnum():\n",
    "            result_string += c\n",
    "    list3.append(result_string.strip())\n",
    "\n",
    "# 주로 브랜드명이 첫 어절에 온다고 판단. 첫 어절로 브랜드 컬럼 생성\n",
    "list4 = []\n",
    "for item in list3:\n",
    "    list4.append(item.split(\" \")[0])\n",
    "실적데이터['브랜드'] = pd.Series(list4)\n",
    "\n",
    "# 브랜드별 점수 매기기\n",
    "# 브랜드별 평균 주문량 계산\n",
    "df_temp = 실적데이터.pivot_table(\n",
    "    index=['브랜드'], values='주문량', aggfunc='count').sort_values(by='주문량', ascending=False)\n",
    "# minmaxscaler로 0~1 사이값으로 scale 조정\n",
    "df_temp1 = pd.DataFrame(\n",
    "    MinMaxScaler().fit_transform(df_temp), index=df_temp.index)\n",
    "\n",
    "# 브랜드별 평균 주문량을 scale 조절한 값을 브랜드 점수로 산정. 브랜드점수 컬럼 생성\n",
    "df_temp1 = df_temp1.reset_index()\n",
    "실적데이터 = pd.merge(실적데이터, df_temp1, on='브랜드')\n",
    "실적데이터.rename({0: '브랜드점수'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. 파생변수 생성을 위한 그래프 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 시간별 상품군별 주문량/방송횟수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "상품별_시간별_주문량=실적데이터.pivot_table(index=['시'],columns='상품군',values='주문량', aggfunc='mean')\n",
    "상품별_시간별_갯수=실적데이터.pivot_table(index=['시'],columns='상품군',values='주문량', aggfunc='count')\n",
    "상품별_시간별_주문량.fillna(0, inplace=True)\n",
    "상품별_시간별_갯수.fillna(0, inplace=True)\n",
    "\n",
    "# 비어있는 시간 제거 후 시간별 재정리\n",
    "temp1=상품별_시간별_주문량.loc[6:23]\n",
    "temp2=상품별_시간별_주문량.loc[0:2]\n",
    "상품별_시간별_주문량=pd.concat([temp1,temp2], axis=0)\n",
    "temp1=상품별_시간별_갯수.loc[6:23]\n",
    "temp2=상품별_시간별_갯수.loc[0:2]\n",
    "상품별_시간별_갯수=pd.concat([temp1,temp2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상품별 시간별 평균 주문량 그래프\n",
    "plt.figure(figsize=(10,40))\n",
    "for i, item in enumerate(list(상품별_시간별_주문량.columns)):\n",
    "    plt.subplot(12,1,i+1)\n",
    "    상품별_시간별_주문량[item].plot(kind='bar')\n",
    "    plt.xlabel(item)\n",
    "plt.savefig('상품별 시간별 평균 주문량.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상품군별 시간별 방송횟수 그래프\n",
    "plt.figure(figsize=(10,40))\n",
    "for i, item in enumerate(list(상품별_시간별_갯수.columns)):\n",
    "    plt.subplot(12,1,i+1)\n",
    "    상품별_시간별_갯수[item].plot(kind='bar')\n",
    "    plt.xlabel(item)\n",
    "plt.savefig('상품군별 시간별 방송횟수.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 요일별 상품군별 주문량 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "상품별_요일별_주문량=실적데이터.pivot_table(index=['요일'],columns='상품군',values='주문량', aggfunc='mean')\n",
    "상품별_요일별_주문량.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상품별 요일별 평균 주문량 그래프\n",
    "상품별_요일별_주문량.plot(kind='line',figsize=(20,10), fontsize=18)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1), fontsize=18)\n",
    "plt.xticks([0,1,2,3,4,5,6],['월','화','수','목','금','토','일'])\n",
    "plt.savefig('상품군별 요일별 평균 주문량.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 월별 상품군별 주문량 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "상품별_월별_주문량=실적데이터.pivot_table(index=['월'],columns='상품군',values='주문량', aggfunc='mean')\n",
    "상품별_월별_주문량.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상품별 요일별 평균 주문량 그래프\n",
    "상품별_월별_주문량.plot(kind='line',figsize=(20,10), fontsize=18)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1), fontsize=18)\n",
    "plt.savefig('상품군별 월별 평균 주문량.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 주별 상품군별 주문량 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "상품별_주별_주문량=실적데이터.pivot_table(index=['주'],columns='상품군',values='주문량', aggfunc='mean')\n",
    "상품별_주별_주문량.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상품별 주별 평균 주문량 그래프\n",
    "상품별_주별_주문량.plot(kind='line',figsize=(20,10), fontsize=18)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1), fontsize=18)\n",
    "plt.savefig('상품군별 주별 평균 주문량.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 상품가격대별 주문량 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "상품가격 = pd.qcut(실적데이터.판매단가,4)\n",
    "le = pp.LabelEncoder()\n",
    "상품가격대 = le.fit_transform(상품가격)\n",
    "실적데이터['상품가격대'] = 상품가격대\n",
    "shuffledSplit = StratifiedShuffleSplit(test_size=0.3)\n",
    "\n",
    "for train_idx, test_idx in shuffledSplit.split(실적데이터, 실적데이터.상품가격대):\n",
    "    train_set = 실적데이터.loc[train_idx]\n",
    "    test_set = 실적데이터.loc[test_idx]\n",
    "\n",
    "train_set.drop('상품가격대', axis=1, inplace=True)\n",
    "test_set.drop('상품가격대', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "상품가격대별_주문량=실적데이터.pivot_table(index=['상품가격대'],values='주문량', aggfunc='mean')\n",
    "상품가격대별_주문량.fillna(0, inplace=True)\n",
    "상품가격대별_주문량.plot(kind='line')\n",
    "plt.savefig('상품가격대별 평균 주문량.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 상품별 판매단가 분포 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "plt.scatter(실적데이터.상품코드, 실적데이터.판매단가)\n",
    "plt.savefig('상품별 판매단가 분포 그래프.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 상품별 노출시간 분포 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(실적데이터.상품코드, 실적데이터.노출)\n",
    "plt.savefig('상품별 노출시간 분포 그래프.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) 상품별 방송시간대 분포 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(실적데이터.상품코드, 실적데이터.시, alpha=0.01)\n",
    "plt.savefig('상품별 방송시간 분포 그래프.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) 브랜드파워 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브랜드 파워 그래프\n",
    "실적데이터.pivot_table(index=['브랜드'],values='주문량', aggfunc='mean').sort_values(by='주문량', ascending=False).plot(figsize=(15,10), kind='bar')\n",
    "plt.savefig('브랜드파워 그래프.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수의 각 항목을 컬럼화\n",
    "\n",
    "# 상품군\n",
    "상품군_df=pd.get_dummies(실적데이터.상품군)\n",
    "실적데이터=pd.concat([실적데이터, 상품군_df],axis=1)\n",
    "\n",
    "# 마더코드\n",
    "실적데이터.마더코드=실적데이터.마더코드-100000\n",
    "\n",
    "마더코드_df=pd.get_dummies(실적데이터.마더코드)\n",
    "마더코드=[]\n",
    "마더코드_max=실적데이터.마더코드.max()\n",
    "마더코드1=[str(i)+\"마더코드\" for i in range(0,마더코드_max+1)]\n",
    "for i in 마더코드_df.columns:\n",
    "    마더코드.append(str(i)+'마더코드')\n",
    "마더코드_df.columns=마더코드\n",
    "for i in [item for item in 마더코드1 if item not in 마더코드]:\n",
    "    마더코드_df[i]=[0 for i in range(len(실적데이터))]\n",
    "마더코드_df=마더코드_df[마더코드1]\n",
    "실적데이터=pd.concat([실적데이터, 마더코드_df],axis=1)\n",
    "\n",
    "# 상품코드\n",
    "실적데이터.상품코드=실적데이터.상품코드-200000\n",
    "\n",
    "상품코드_df=pd.get_dummies(실적데이터.상품코드)\n",
    "상품코드=[]\n",
    "상품코드_max=실적데이터.상품코드.max()\n",
    "상품코드1=[str(i)+\"상품코드\" for i in range(0,상품코드_max+1)]\n",
    "for i in 상품코드_df.columns:\n",
    "    상품코드.append(str(i)+'상품코드')\n",
    "상품코드_df.columns=상품코드\n",
    "for i in [item for item in 상품코드1 if item not in 상품코드]:\n",
    "    상품코드_df[i]=[0 for i in range(len(실적데이터))]\n",
    "상품코드_df=상품코드_df[상품코드1]\n",
    "실적데이터=pd.concat([실적데이터, 상품코드_df],axis=1)\n",
    "\n",
    "# 월\n",
    "월_df=pd.get_dummies(실적데이터.월)\n",
    "월=[]\n",
    "월1=[str(i)+\"월\" for i in range(1,13)]\n",
    "for i in 월_df.columns:\n",
    "    월.append(str(i)+'월')\n",
    "월_df.columns=월\n",
    "for i in [item for item in 월1 if item not in 월]:\n",
    "    월_df[i]=[0 for i in range(len(실적데이터))]\n",
    "월_df=월_df[월1]\n",
    "실적데이터=pd.concat([실적데이터, 월_df],axis=1)\n",
    "\n",
    "#일\n",
    "일_df=pd.get_dummies(실적데이터.일)\n",
    "일=[]\n",
    "일1=[str(i)+'일' for i in range(1,32)]\n",
    "for i in 일_df.columns:\n",
    "    일.append(str(i)+'일')\n",
    "일_df.columns=일\n",
    "for i in [item for item in 일1 if item not in 일]:\n",
    "    일_df[i]=[0 for i in range(len(실적데이터))]\n",
    "일_df=일_df[일1]\n",
    "실적데이터=pd.concat([실적데이터, 일_df],axis=1)\n",
    "\n",
    "#요일\n",
    "요일_df=pd.get_dummies(실적데이터.요일)\n",
    "요일=[]\n",
    "요일1=['월요일', '화요일', '수요일', '목요일', '금요일', '토요일', '일요일']\n",
    "for i in 요일_df.columns:\n",
    "    요일.append(요일1[i])\n",
    "요일_df.columns=요일\n",
    "for i in [item for item in 요일1 if item not in 요일]:\n",
    "    요일_df[i]=[0 for i in range(len(실적데이터))]\n",
    "요일_df=요일_df[요일1]\n",
    "실적데이터=pd.concat([실적데이터, 요일_df],axis=1)\n",
    "\n",
    "#주\n",
    "주_df=pd.get_dummies(실적데이터.주)\n",
    "주=[]\n",
    "주1=[str(i)+\"주\" for i in range(1,53)]\n",
    "for i in 주_df.columns:\n",
    "    주.append(str(i)+'주')\n",
    "주_df.columns=주\n",
    "for i in [item for item in 주1 if item not in 주]:\n",
    "    주_df[i]=[0 for i in range(len(실적데이터))]\n",
    "주_df=주_df[주1]\n",
    "실적데이터=pd.concat([실적데이터, 주_df],axis=1)\n",
    "\n",
    "#시\n",
    "시_df=pd.get_dummies(실적데이터.시)\n",
    "시=[]\n",
    "시1=[str(i)+\"시\" for i in range(0,24)]\n",
    "for i in 시_df.columns:\n",
    "    시.append(str(i)+'시')\n",
    "시_df.columns=시\n",
    "for i in [item for item in 시1 if item not in 시]:\n",
    "    시_df[i]=[0 for i in range(len(실적데이터))]\n",
    "시_df=시_df[시1]\n",
    "실적데이터=pd.concat([실적데이터, 시_df],axis=1)\n",
    "\n",
    "#분\n",
    "분_df=pd.get_dummies(실적데이터.분)\n",
    "분=[]\n",
    "분1=[str(i)+\"분\" for i in range(0,60,5)]\n",
    "for i in 분_df.columns:\n",
    "    분.append(str(i)+'분')\n",
    "분_df.columns=분\n",
    "for i in [item for item in 분1 if item not in 분]:\n",
    "    분_df[i]=[0 for i in range(len(실적데이터))]\n",
    "분_df=분_df[분1]\n",
    "실적데이터=pd.concat([실적데이터, 분_df],axis=1)\n",
    "\n",
    "# 그외 데이터 스케일링(단위 낮춤)\n",
    "실적데이터.판매단가=실적데이터.판매단가/100000\n",
    "실적데이터.종가=실적데이터.종가/10000\n",
    "실적데이터.노출=실적데이터.노출/60\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "실적데이터.drop(['마더코드', '상품코드', '월', '일', '요일', '주' , '시', '분','상품군'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없는 변수 삭제\n",
    "실적데이터.drop(['평균최고기온(℃)', '평균최저기온(℃)', '평균일강수량(mm)', '최대풍속(m/s)', '분당평균시청률', '분당최고시청률',\n",
    "            '종가', '취급액', '방송일시', '상품명', '일시', '브랜드', '시간', '방송시간','상품가격대'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종속변수와 독립변수 분리\n",
    "X = 실적데이터.drop(['주문량'], axis=1)\n",
    "y = 실적데이터['주문량']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(max_depth=17, min_samples_leaf=3, min_samples_split=3,\n",
    "                      n_estimators=800)\n",
    "rf_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf_reg.predict(X_test)\n",
    "mse = mt.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = mt.r2_score(y_test, y_pred)\n",
    "print(mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_reg = DecisionTreeRegressor()\n",
    "dt_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=dt_reg.predict(X_test)\n",
    "mse = mt.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = mt.r2_score(y_test, y_pred)\n",
    "print(mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = XGBRegressor(n_estimator = 500, gamma=0, learning_rate=0.4, max_depth=10, n_jobs=-1, objective ='reg:squarederror')\n",
    "xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=xgb_reg.predict(X_test)\n",
    "mse = mt.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = mt.r2_score(y_test, y_pred)\n",
    "print(mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다층신경망(MLPRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(10,10,10), max_iter=200, solver='adam', objective ='reg:squarederror')\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "mse = mt.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = mt.r2_score(y_test, y_pred)\n",
    "print(mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg = AdaBoostRegressor(base_estimator=None, learning_rate=0.05, loss='exponential',\n",
    "         n_estimators=100, random_state=0) \n",
    "ada_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "mse = mt.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = mt.r2_score(y_test, y_pred)\n",
    "print(mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_reg = LGBMRegressor()\n",
    "\n",
    "X_trian1 = X_train.copy()\n",
    "num = len(X_trian1.columns) # len 뽑아서 열을 숫자 형태로 바꿔줘야 모델 학습 가능\n",
    "cols = []\n",
    "for i in range(num):\n",
    "        cols.append(str(i))\n",
    "X_trian1.columns = cols\n",
    "\n",
    "lgbm_reg.fit(X_trian1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_reg.predict(X_test)\n",
    "mse = mt.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = mt.r2_score(y_test, y_pred)\n",
    "print(mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  인공신경망(Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=X_train.shape[1:]\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=n, kernel_initializer='normal'),\n",
    "    keras.layers.Dense(16, activation='relu', kernel_initializer='normal'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=10, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test)\n",
    "print(f'\\nLoss : {loss_and_metrics[0]:6}')\n",
    "print(f'mae : {loss_and_metrics[1]:6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "mse = mt.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = mt.r2_score(y_test, y_pred)\n",
    "print(mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. GridSearchCV를 이용한 하이퍼파라미터 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = {\n",
    "    'subsample': [0.4, 0.6],                   #  2\n",
    "    'min_child_weight':[1, 5, 10],             #  3\n",
    "    'gamma':[0.5, 1, 1.5, 2, 5],               #  4\n",
    "    'max_depth':[4,10,15],                     #  3\n",
    "    'eta':[0.05, 0.01,  0.1, 0.3]              #  4\n",
    "}\n",
    "xgb = XGBRegressor()\n",
    "grid_xgb = GridSearchCV(xgb, param_grid=xgb_param, scoring='r2', cv=5)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "print('final params', grid_xgb.best_params_)   # 최적의 파라미터 값 출력\n",
    "print('best score', grid_xgb.best_score_)      # 최고의 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_xgb.predict(X_test)\n",
    "mse = mt.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = mt.r2_score(y_test, y_pred)\n",
    "print(mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "rf_params = { 'n_estimators' : [700,800,1000],\n",
    "           'max_depth' : [8,14,17],\n",
    "           'min_samples_leaf' : [1,3],\n",
    "           'min_samples_split' : [2,3,7]            }\n",
    "grid_reg = GridSearchCV(rf_reg, param_grid = rf_params, scoring='r2',cv=5)\n",
    "grid_reg.fit(X_train,y_train)\n",
    "\n",
    "print('final params', grid_reg.best_params_)   # 최적의 파라미터 값 출력\n",
    "print('best score', grid_reg.best_score_)      # 최고의 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_reg.predict(X_test)\n",
    "mse = mt.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = mt.r2_score(y_test, y_pred)\n",
    "print(mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-1. Kfold 교차검증(nn에 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn_keras(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = None\n",
    "        self.result = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = keras.models.Sequential([\n",
    "                keras.layers.Dense(32, activation='relu', input_shape=X_train.shape[1:], kernel_initializer='normal'),\n",
    "                keras.layers.Dense(16, activation='relu', kernel_initializer='normal'),\n",
    "                keras.layers.Dense(1)\n",
    "            ])\n",
    "        self.model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='mse', metrics=['mae'])\n",
    "        self.result = self.model.fit(X_train, y_train, epochs=30, batch_size=10, validation_split=0.2, verbose=1)\n",
    "        \n",
    "    def predict(self, new_data):\n",
    "        return self.model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "cv = KFold(5, shuffle=True, random_state=0)\n",
    "model=nn_keras()\n",
    "results = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "print(\"Results: %.3f (%.3f) MAE\" % (results.mean(), results.std()))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 평가데이터 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "평가데이터.rename(columns={'노출(분)' : '노출'}, inplace=True)\n",
    "\n",
    "# 결측값 처리 \n",
    "# 1. 판매단가가 0인 데이터 제거\n",
    "평가데이터.취급액.fillna(0, inplace=True)\n",
    "\n",
    "# 2. 노출값이 nan인 항목은 바로 위 항목으로 채우기\n",
    "평가데이터.노출.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# 판매가 0워인 데이터 예측 제외\n",
    "평가데이터=평가데이터[평가데이터.판매단가!=0]\n",
    "\n",
    "# 날짜 컬럼 나누기\n",
    "평가데이터['월']=평가데이터.방송일시.dt.month\n",
    "평가데이터['일']=평가데이터.방송일시.dt.day\n",
    "평가데이터['요일']=평가데이터.방송일시.dt.weekday\n",
    "평가데이터['주']=평가데이터.방송일시.dt.week\n",
    "평가데이터['시간']=평가데이터.방송일시.dt.time\n",
    "평가데이터['시']=평가데이터.방송일시.dt.hour\n",
    "평가데이터['분']=평가데이터.방송일시.dt.minute\n",
    "\n",
    "# 실적데이터['시간'] = 실적데이터.시간.apply(lambda x : str(x)).apply(lambda x : int(x.split(':')[0])*60 + int(x.split(':')[1]))\n",
    "\n",
    "평가데이터['방송날짜'] = 평가데이터.방송일시.apply(lambda x : str(x)).apply(lambda x : x.split(' ')[0])\n",
    "평가데이터['방송시간'] = 평가데이터.방송일시.apply(lambda x : str(x)).apply(lambda x : x.split(' ')[1][:-3])\n",
    "\n",
    "평가데이터 = 평가데이터.drop(['방송시간'],axis=1)\n",
    "평가데이터=평가데이터.rename(columns={'방송날짜':'일시'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브랜드 컬럼\n",
    "\n",
    "# 상품명에서 불필요한 단어 제거\n",
    "list1 = []\n",
    "for item in 평가데이터[['상품명']].values:\n",
    "    for i in ['(직매입)', '일시불', '무이자', '도냄', 'a4', '뉴', '(일)', '(무)', '특집', '(쿠)',\n",
    "              '초특가''(세일20%)', '1세트', '2세트', '(더블+더블)', '(더블+싱글)', '(더블사이즈)', \n",
    "              '(싱글사이즈)', '(점보특대형)', '(점보형)', '(중형)', '(퀸+퀸)', '(퀸+싱글)', '(싱글+싱글)', \n",
    "              '(킹사이즈)', '(퀸사이즈)', '[완벽더블]', '파격가', '초특가', '무)', '(렌탈)', '국내산']:\n",
    "        item[0] = item[0].replace(i, \"\")\n",
    "    list1.append(item[0].strip())\n",
    "\n",
    "# 숫자, 영어, 한글을 제외한 문자 제거\n",
    "list3 = []\n",
    "for i in list1:\n",
    "    result_string = \"\"\n",
    "    for c in i:\n",
    "        if c == \" \":\n",
    "            result_string += c\n",
    "        elif c.isalnum():\n",
    "            result_string += c\n",
    "    list3.append(result_string.strip())\n",
    "\n",
    "# 주로 브랜드명이 첫 어절에 온다고 판단. 첫 어절로 브랜드 컬럼 생성\n",
    "list4 = []\n",
    "for item in list3:\n",
    "    list4.append(item.split(\" \")[0])\n",
    "평가데이터['브랜드'] = pd.Series(list4)\n",
    "\n",
    "# 브랜드별 점수 매기기\n",
    "# 브랜드별 평균 주문량 계산\n",
    "df_temp2 = 평가데이터.pivot_table(\n",
    "    index=['브랜드'], values='판매단가', aggfunc='count').sort_values(by='판매단가', ascending=False)\n",
    "# minmaxscaler로 0~1 사이값으로 scale 조정\n",
    "df_temp3 = pd.DataFrame(\n",
    "    MinMaxScaler().fit_transform(df_temp2), index=df_temp2.index)\n",
    "\n",
    "# # 브랜드별 평균 주문량을 scale 조절한 값을 브랜드 점수로 산정. 브랜드점수 컬럼 생성\n",
    "# df_temp1 = df_temp1.reset_index()\n",
    "평가데이터 = pd.merge(평가데이터, df_temp1, on='브랜드')\n",
    "평가데이터.rename({0: '브랜드점수'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "평가데이터_feature = 평가데이터.drop(['취급액', '방송일시', '상품명', '일시','브랜드','시간'], axis=1)\n",
    "실적데이터_target= 실적데이터['주문량']\n",
    "\n",
    "상품군_df=pd.get_dummies(평가데이터.상품군)\n",
    "평가데이터=pd.concat([평가데이터, 상품군_df],axis=1)\n",
    "\n",
    "평가데이터_feature.마더코드=평가데이터_feature.마더코드-100000\n",
    "평가데이터_feature.상품코드=평가데이터_feature.상품코드-200000\n",
    "\n",
    "마더코드_df=pd.get_dummies(평가데이터_feature.마더코드)\n",
    "마더코드=[]\n",
    "마더코드1=[str(i)+\"마더코드\" for i in range(0,마더코드_max+1)]\n",
    "for i in 마더코드_df.columns:\n",
    "    마더코드.append(str(i)+'마더코드')\n",
    "마더코드_df.columns=마더코드\n",
    "for i in [item for item in 마더코드1 if item not in 마더코드]:\n",
    "    마더코드_df[i]=[0 for i in range(len(평가데이터_feature))]\n",
    "마더코드_df=마더코드_df[마더코드1]\n",
    "평가데이터_feature=pd.concat([평가데이터_feature, 마더코드_df],axis=1)\n",
    "\n",
    "상품코드_df=pd.get_dummies(평가데이터_feature.상품코드)\n",
    "상품코드=[]\n",
    "상품코드1=[str(i)+\"상품코드\" for i in range(0,상품코드_max+1)]\n",
    "for i in 상품코드_df.columns:\n",
    "    상품코드.append(str(i)+'상품코드')\n",
    "상품코드_df.columns=상품코드\n",
    "for i in [item for item in 상품코드1 if item not in 상품코드]:\n",
    "    상품코드_df[i]=[0 for i in range(len(평가데이터_feature))]\n",
    "상품코드_df=상품코드_df[상품코드1]\n",
    "평가데이터_feature=pd.concat([평가데이터_feature, 상품코드_df],axis=1)\n",
    "\n",
    "\n",
    "월_df=pd.get_dummies(평가데이터_feature.월)\n",
    "월=[]\n",
    "월1=[str(i)+\"월\" for i in range(1,13)]\n",
    "for i in 월_df.columns:\n",
    "    월.append(str(i)+'월')\n",
    "월_df.columns=월\n",
    "for i in [item for item in 월1 if item not in 월]:\n",
    "    월_df[i]=[0 for i in range(len(평가데이터_feature))]\n",
    "월_df=월_df[월1]\n",
    "평가데이터_feature=pd.concat([평가데이터_feature, 월_df],axis=1)\n",
    "\n",
    "일_df=pd.get_dummies(평가데이터_feature.일)\n",
    "일=[]\n",
    "일1=[str(i)+'일' for i in range(1,32)]\n",
    "for i in 일_df.columns:\n",
    "    일.append(str(i)+'일')\n",
    "일_df.columns=일\n",
    "for i in [item for item in 일1 if item not in 일]:\n",
    "    일_df[i]=[0 for i in range(len(평가데이터_feature))]\n",
    "일_df=일_df[일1]\n",
    "평가데이터_feature=pd.concat([평가데이터_feature, 일_df],axis=1)\n",
    "\n",
    "요일_df=pd.get_dummies(평가데이터_feature.요일)\n",
    "요일=[]\n",
    "요일1=['월요일', '화요일', '수요일', '목요일', '금요일', '토요일', '일요일']\n",
    "for i in 요일_df.columns:\n",
    "    요일.append(요일1[i])\n",
    "요일_df.columns=요일\n",
    "for i in [item for item in 요일1 if item not in 요일]:\n",
    "    요일_df[i]=[0 for i in range(len(평가데이터_feature))]\n",
    "요일_df=요일_df[요일1]\n",
    "평가데이터_feature=pd.concat([평가데이터_feature, 요일_df],axis=1)\n",
    "\n",
    "주_df=pd.get_dummies(평가데이터_feature.주)\n",
    "주=[]\n",
    "주1=[str(i)+\"주\" for i in range(1,53)]\n",
    "for i in 주_df.columns:\n",
    "    주.append(str(i)+'주')\n",
    "주_df.columns=주\n",
    "for i in [item for item in 주1 if item not in 주]:\n",
    "    주_df[i]=[0 for i in range(len(평가데이터_feature))]\n",
    "주_df=주_df[주1]\n",
    "평가데이터_feature=pd.concat([평가데이터_feature, 주_df],axis=1)\n",
    "\n",
    "시_df=pd.get_dummies(평가데이터_feature.시)\n",
    "시=[]\n",
    "시1=[str(i)+\"시\" for i in range(0,24)]\n",
    "for i in 시_df.columns:\n",
    "    시.append(str(i)+'시')\n",
    "시_df.columns=시\n",
    "for i in [item for item in 시1 if item not in 시]:\n",
    "    시_df[i]=[0 for i in range(len(평가데이터_feature))]\n",
    "시_df=시_df[시1]\n",
    "평가데이터_feature=pd.concat([평가데이터_feature, 시_df],axis=1)\n",
    "\n",
    "분_df=pd.get_dummies(평가데이터_feature.분)\n",
    "분=[]\n",
    "분1=[str(i)+\"분\" for i in range(0,60,5)]\n",
    "for i in 분_df.columns:\n",
    "    분.append(str(i)+'분')\n",
    "분_df.columns=분\n",
    "for i in [item for item in 분1 if item not in 분]:\n",
    "    분_df[i]=[0 for i in range(len(평가데이터_feature))]\n",
    "분_df=분_df[분1]\n",
    "평가데이터_feature=pd.concat([평가데이터_feature, 분_df],axis=1)\n",
    "\n",
    "\n",
    "평가데이터_feature.판매단가=평가데이터_feature.판매단가/100000\n",
    "평가데이터_feature.노출=평가데이터_feature.노출/60\n",
    "\n",
    "평가데이터_feature = 평가데이터_feature.drop(['마더코드', '상품코드', '월', '일', '요일', '주' , '시', '분','상품군'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX=평가데이터_feature.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공신경망을 이용하여 학습데이터를 학습 후 평가데이터 예측\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=X_train.shape[1:], kernel_initializer='normal'),\n",
    "    keras.layers.Dense(16, activation='relu', kernel_initializer='normal'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=10, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(testX)\n",
    "평가데이터['주문량']=pd.DataFrame(y_pred, columns=['주문량'])\n",
    "평가데이터['취급액']=평가데이터.주문량*평가데이터.판매단가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가데이터 예측취급액 넣어서 저장\n",
    "평가데이터2=평가데이터1.copy()\n",
    "평가데이터2.drop('취급액',axis=1,inplace=True)\n",
    "평가데이터2=pd.merge(평가데이터2,평가데이터[['방송일시','상품명','취급액']], on=['방송일시','상품명'], how='left')\n",
    "평가데이터2.취급액.fillna(0, inplace=True)\n",
    "평가데이터1.to_csv(r'./평가데이터_예측.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 예측을 토대로 요일별 시간별 상품군별 최적방안 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio25 = int(len(평가데이터) * 0.25)\n",
    "for item in 평가데이터.상품군.unique():\n",
    "    plt.figure()\n",
    "    평가데이터[평가데이터.상품군 == item].sort_values(by='취급액', ascending=False).시[:ratio25].value_counts().plot(kind='bar')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.xlabel(item)\n",
    "    plt.savefig('data/{}시간.png'.format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio25 = int(len(평가데이터) * 0.25)\n",
    "for item in 평가데이터.상품군.unique():\n",
    "    plt.figure()\n",
    "    temp=평가데이터[평가데이터.상품군 == item].sort_values(by='취급액', ascending=False).요일[:ratio25].value_counts()\n",
    "    temp.rename({0:'월',1:'화',2:'수',3:'목',4:'금',5:'토',6:'일'},axis=0,inplace=True)\n",
    "    temp.plot(kind='bar')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.xlabel(item)\n",
    "    plt.savefig('data/{}요일.png'.format(item))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
